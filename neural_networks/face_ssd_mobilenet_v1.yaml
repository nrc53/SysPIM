network_name: ssd_mobilenet_v1
network_type: object_detection
inp_dims: [512, 512, 3]
layers:
  conv_1:
    type: conv_normal
    kernel: [3, 3, 3, 32]
    stride: 2
    padding: 1
    norm: batch_norm
    activation: ReLu
    input: prev_layer 
    output: [conv_2]
    num: 0 
  conv_2:
    type: conv_dw
    kernel: [3, 3, 32]
    stride: 1
    padding: 2
    norm: batch_norm
    activation: ReLu
    input: prev_layer  
    output: [conv_3]
    num: 1 
  conv_3:
    type: conv_normal
    kernel: [1, 1, 32, 64]
    stride: 1
    padding: 0
    norm: batch_norm
    activation: ReLu
    input: prev_layer
    output: [conv_4]
    num: 2   
  conv_4:
    type: conv_dw
    kernel: [3, 3, 64]
    stride: 2
    padding: 1
    norm: batch_norm
    activation: ReLu
    input: prev_layer
    output: [conv_5]
    num: 3 
  conv_5:
    type: conv_normal
    kernel: [1, 1, 64, 128]
    stride: 1
    padding: 0
    norm: batch_norm
    activation: ReLu
    input: prev_layer
    output: [conv_6]
    num: 4
  conv_6:
    type: conv_dw
    kernel: [3, 3, 128]
    stride: 1
    padding: 2
    norm: batch_norm
    activation: ReLu
    input: prev_layer
    output: [conv_7]
    num: 5
  conv_7:
    type: conv_normal
    kernel: [1, 1, 128, 128]
    stride: 1
    padding: 0
    norm: batch_norm
    activation: ReLu
    input: prev_layer
    output: [conv_8]
    num: 6 
  conv_8:
    type: conv_dw
    kernel: [3, 3, 128]
    stride: 2
    padding: 1
    norm: batch_norm
    activation: ReLu
    input: prev_layer
    output: [conv_9]
    num: 7 
  conv_9:
    type: conv_normal
    kernel: [1, 1, 128, 256]
    stride: 1
    padding: 0
    norm: batch_norm
    activation: ReLu
    input: prev_layer
    output: [conv_10]
    num: 8 
  conv_10:
    type: conv_dw
    kernel: [3, 3, 256]
    stride: 1
    padding: 2
    norm: batch_norm
    activation: ReLu
    input: prev_layer
    output: [conv_11]
    num: 9 
  conv_11:
    type: conv_normal
    kernel: [1, 1, 256, 256]
    stride: 1
    padding: 0
    norm: batch_norm
    activation: ReLu
    input: prev_layer
    output: [conv_12]
    num: 10 
  conv_12:
    type: conv_dw
    kernel: [3, 3, 256]
    stride: 2
    padding: 1
    norm: batch_norm
    activation: ReLu
    input: prev_layer
    output: [conv_13]
    num: 11 
  conv_13:
    type: conv_normal
    kernel: [1, 1, 256, 512]
    stride: 1
    padding: 0
    norm: batch_norm
    activation: ReLu
    input: prev_layer
    output: [conv_14]
    num: 12 
  conv_14:
    type: conv_dw
    kernel: [3, 3, 512]
    stride: 1
    padding: 2
    norm: batch_norm
    activation: ReLu
    input: prev_layer
    output: [conv_15]
    num: 13 
  conv_15:
    type: conv_normal
    kernel: [1, 1, 512, 512]
    stride: 1
    padding: 0
    norm: batch_norm
    activation: ReLu
    input: prev_layer
    output: [conv_16]
    num: 14 
  conv_16:
    type: conv_dw
    kernel: [3, 3, 512]
    stride: 1
    padding: 2
    norm: batch_norm
    activation: ReLu
    input: prev_layer
    output: [conv_17]
    num: 15 
  conv_17:
    type: conv_normal
    kernel: [1, 1, 512, 512]
    stride: 1
    padding: 0
    norm: batch_norm
    activation: ReLu
    input: prev_layer
    output: [conv_18]
    num: 16 
  conv_18:
    type: conv_dw
    kernel: [3, 3, 512]
    stride: 1
    padding: 2
    norm: batch_norm
    activation: ReLu
    input: prev_layer
    output: [conv_19]
    num: 17 
  conv_19:
    type: conv_normal
    kernel: [1, 1, 512, 512]
    stride: 1
    padding: 0
    norm: batch_norm
    activation: ReLu
    input: prev_layer
    output: [conv_20]
    num: 18 
  conv_20:
    type: conv_dw
    kernel: [3, 3, 512]
    stride: 1
    padding: 2
    norm: batch_norm
    activation: ReLu
    input: prev_layer
    output: [conv_21]
    num: 19 
  conv_21:
    type: conv_normal
    kernel: [1, 1, 512, 512]
    stride: 1
    padding: 0
    norm: batch_norm
    activation: ReLu
    input: prev_layer
    output: [conv_22]
    num: 20 
  conv_22:
    type: conv_dw
    kernel: [3, 3, 512]
    stride: 1
    padding: 2
    norm: batch_norm
    activation: ReLu
    input: prev_layer
    output: [conv_23]
    num: 21 
  conv_23:
    type: conv_normal
    kernel: [1, 1, 512, 512]
    stride: 1
    padding: 0
    norm: batch_norm
    activation: ReLu
    input: prev_layer
    output: [conv_24, class_predictor_1, box_predictor_1]
    num: 22 
  conv_24:
    type: conv_dw
    kernel: [3, 3, 512]
    stride: 2
    padding: 1
    norm: batch_norm
    activation: ReLu
    input: prev_layer
    output: [conv_25]
    num: 23 
  conv_25:
    type: conv_normal
    kernel: [1, 1, 512, 1024]
    stride: 1
    padding: 0
    norm: batch_norm
    activation: ReLu
    input: prev_layer
    output: [conv_26]
    num: 24 
  conv_26:
    type: conv_dw
    kernel: [3, 3, 1024]
    stride: 1
    padding: 2
    norm: batch_norm
    activation: ReLu
    input: prev_layer
    output: [conv_27]
    num: 25 
  conv_27:
    type: conv_normal
    kernel: [1, 1, 1024, 1024]
    stride: 1
    padding: 0
    norm: batch_norm
    activation: ReLu
    input: prev_layer
    output: [conv_28, class_predictor_2, box_predictor_2]
    num: 26 
  conv_28:
    type: conv_normal
    kernel: [1, 1, 1024, 256]
    stride: 1
    padding: 0
    norm: batch_norm
    activation: ReLu
    input: prev_layer
    output: [conv_29]
    num: 27 
  conv_29:
    type: conv_normal
    kernel: [3, 3, 256, 512]
    stride: 2
    padding: 1
    norm: batch_norm
    activation: ReLu
    input: prev_layer
    output: [conv_30, class_predictor_3, box_predictor_3]
    num: 28 
  conv_30:
    type: conv_normal
    kernel: [1, 1, 512, 128]
    stride: 1
    padding: 0
    norm: batch_norm
    activation: ReLu
    input: prev_layer
    output: [conv_31]
    num: 29 
  conv_31:
    type: conv_normal
    kernel: [3, 3, 128, 256]
    stride: 2
    padding: 1
    norm: batch_norm
    activation: ReLu
    input: prev_layer
    output: [conv_32, class_predictor_4, box_predictor_4]
    num: 30 
  conv_32:
    type: conv_normal
    kernel: [1, 1, 256, 128]
    stride: 1
    padding: 0
    norm: batch_norm
    activation: ReLu
    input: prev_layer
    output: [conv_33]
    num: 31 
  conv_33:
    type: conv_normal
    kernel: [3, 3, 128, 256]
    stride: 2
    padding: 1
    norm: batch_norm
    activation: ReLu
    input: prev_layer
    output: [conv_34, class_predictor_5, box_predictor_5]
    num: 32 
  conv_34:
    type: conv_normal
    kernel: [1, 1, 256, 64]
    stride: 1
    padding: 0
    norm: batch_norm
    activation: ReLu
    input: prev_layer
    output: [conv_35]
    num: 33 
  conv_35:
    type: conv_normal
    kernel: [3, 3, 64, 128]
    stride: 2
    padding: 1
    norm: batch_norm
    activation: ReLu
    input: prev_layer
    output: [class_predictor_6, box_predictor_6]
    num: 34 
  class_predictor_1:
    type: conv_normal
    kernel: [1, 1, 512, 9]
    stride: 1
    padding: 0
    norm: batch_norm
    activation: ReLu
    input: conv_23
    output: []
    num: 35 
  box_predictor_1:
    type: conv_normal
    kernel: [1, 1, 512, 12]
    stride: 1
    padding: 0
    norm: batch_norm
    activation: ReLu
    input: conv_23
    output: []
    num: 36 
  class_predictor_2:
    type: conv_normal
    kernel: [1, 1, 1024, 18]
    stride: 1
    padding: 0
    norm: batch_norm
    activation: ReLu
    input: conv_27
    output: []
    num: 37
  box_predictor_2:
    type: conv_normal
    kernel: [1, 1, 1024, 24]
    stride: 1
    padding: 0
    norm: batch_norm
    activation: ReLu
    input: conv_27
    output: []
    num: 38
  class_predictor_3:
    type: conv_normal
    kernel: [1, 1, 512, 18]
    stride: 1
    padding: 0
    norm: batch_norm
    activation: ReLu
    input: conv_29
    output: []
    num: 39 
  box_predictor_3:
    type: conv_normal
    kernel: [1, 1, 512, 24]
    stride: 1
    padding: 0
    norm: batch_norm
    activation: ReLu
    input: conv_29
    output: []
    num: 40
  class_predictor_4:
    type: conv_normal
    kernel: [1, 1, 256, 18]
    stride: 1
    padding: 0
    norm: batch_norm
    activation: ReLu
    input: conv_31
    output: []
    num: 41
  box_predictor_4:
    type: conv_normal
    kernel: [1, 1, 256, 24]
    stride: 1
    padding: 0
    norm: batch_norm
    activation: ReLu
    input: conv_31
    output: []
    num: 42 
  class_predictor_5:
    type: conv_normal
    kernel: [1, 1, 256, 18]
    stride: 1
    padding: 0
    norm: batch_norm
    activation: ReLu
    input: conv_33
    output: []
    num: 43
  box_predictor_5:
    type: conv_normal
    kernel: [1, 1, 256, 24]
    stride: 1
    padding: 0
    norm: batch_norm
    activation: ReLu
    input: conv_33
    output: []
    num: 44 
  class_predictor_6:
    type: conv_normal
    kernel: [1, 1, 128, 18]
    stride: 1
    padding: 0
    norm: batch_norm
    activation: ReLu
    input: conv_35
    output: []
    num: 45
  box_predictor_6:
    type: conv_normal
    kernel: [1, 1, 128, 24]
    stride: 1
    padding: 0
    norm: batch_norm
    activation: ReLu
    input: conv_35
    output: []
    num: 46 